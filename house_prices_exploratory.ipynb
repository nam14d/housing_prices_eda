{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## 1.0: General Overview of the Dataset and its Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "source": [
    "### 1.1: First few observations and the dataframe's shape"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "source": [
    "We have 1460 observations in the training dataset and 81 features. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.2: What about missing values? How many are there? Where are they concentrated?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "source": [
    "df.isna().sum().sort_values(ascending = False).head(15)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "There seems to be about 6965 missing values focused on optional additions to a house like pools, fences, firplaces, garages, basements, and miscellaneous features. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.3: Breakdown Of Predictive Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noms = ['MSSubClass','MSZoning', 'Street','Alley','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Foundation','Heating','CentralAir','Electrical','GarageType','MiscFeature','SaleType','SaleCondition']\n",
    "\n",
    "ords = ['ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC','KitchenQual','Functional','FireplaceQu','GarageFinish','GarageQual','GarageCond','PavedDrive','PoolQC','Fence']\n",
    "\n",
    "continuous = ['LotFrontage','MasVnrArea']\n",
    "\n",
    "discrete = ['LotArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','GrLivArea','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','OverallQual','OverallCond','LowQualFinSF','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars', 'YearBuilt','YearRemodAdd','GarageYrBlt','MoSold','YrSold']\n",
    "\n",
    "rest = [item for item in list(df.columns) if item not in list(noms + ords + continuous + discrete)]"
   ]
  },
  {
   "source": [
    "An example of each of the different variable types (nominal, ordinal, discrete, and continuous) found within the dataset:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Neighborhood','ExterQual','LotFrontage','LotArea']].head()"
   ]
  },
  {
   "source": [
    "We have different labels, shown by the Neighborhood feature, several ranking systems, and numerical measurements of different fixtures within the house (both as floats and as integers). Of the four types of features, which are most prominent?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(noms + ords + continuous + discrete)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(['Nominal','Ordinal','Discrete','Continuous'], [(len(noms) / total), (len(ords)/total),(len(discrete)/total),(len(continuous)/total)])\n",
    "plt.title(\"Percentage of Total Variables as Each of the Different Types\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Neighborhood','ExterQual','LotFrontage','LotArea']].dtypes"
   ]
  },
  {
   "source": [
    "The majority of features are categorical; these often need to be converted into a more descriptive datatype (turning the general object into a date or numerical value) during the cleaning phase. Of course, the discrete variables are represented by integers, and those continuous utilize float values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.4: Statistical Summary of the Numerical Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[discrete + continuous].describe()"
   ]
  },
  {
   "source": [
    "Although there is much to take in here, there are important aspects of this dataset to note. First, many features represent optional housing fixtures, which many observations chose to do without. This results in a case where the mean is often a lower value than the standard deviation. See the WoodDeckSF histogram below for an example."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.histplot(df, x=\"WoodDeckSF\", bins=30)\n",
    "plt.title(\"The Distribution of Values in the WoodDeckSF Feature\")"
   ]
  },
  {
   "source": [
    "### 1.5: We are trying to predict the sales price (a continuous variable) of houses in the testing dataset. What does its distribution look like?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df[['SalePrice']].describe().astype('int32')\n",
    "\n",
    "sns.set_palette(sns.color_palette(\"pastel\"))\n",
    "sns.set_style('white')\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Distribution of SalePrice Target Feature\")\n",
    "sns.histplot(data = df, x = \"SalePrice\", bins=30, kde=True, color='green')\n",
    "plt.table(cellText=summary.values, rowLabels=summary.index, colLabels=summary.columns, cellLoc='right', rowLoc='center', loc='right', bbox=[0.79, 0.69, 0.2, 0.3])"
   ]
  },
  {
   "source": [
    "There is a clear right skew in the Sales Prices of these homes. Beyond that, there seem to be a few outliers at the extreme right. Both of these issues should be addressed. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.0: Comparing the Colinearity of the Differing Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.1: Creating a Heat Map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,13))\n",
    "sns.heatmap(df.drop('Id', axis = 1).corr(), mask = np.triu(df.drop('Id', axis = 1).corr()))"
   ]
  },
  {
   "source": [
    "From the looks of it, all of the strong and notable features have a positive connection with the sales price of a house. Below I will gather those relationships are healthy and could not have been made by chance (p-value <= 0.05)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat((df[continuous + discrete], df['SalePrice']), axis = 1).dropna()\n",
    "h1 = {}\n",
    "for column in temp:\n",
    "    corr, pval = pearsonr(temp[column], temp['SalePrice'])\n",
    "    if abs(corr) >= 0.3 and pval <= 0.05:\n",
    "        h1[column] = (pval, corr)\n",
    "dict(sorted(h1.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "source": [
    "The dictionary above represents those features that had a p-value greater than 0.05 and a correlation coefficient greater than 0.3. The latter states that the pair of features            (x and SalePrice) holds a strong relationship, and the former measures whether or not it is statistically significant. Once those hurdles are cleared (and as long as these features do not correlate with each other to a great degree), we can move on. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.2: Choosing Discrete and Continuous Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive = df.corr()[h1.keys()]\n",
    "index = df.corr()[h1.keys()].columns\n",
    "heat = predictive.loc[index]\n",
    "\n",
    "plt.figure(figsize=(13,13))\n",
    "sns.heatmap(heat, mask = np.triu(heat))"
   ]
  },
  {
   "source": [
    "We see that a couple of the features are correlated with each other such as the number of cars in the garage and its size; with that said their correlation coefficient is not greater than 0.9, meaning that there is still a sizeable amount of information that is independent. Let's take a look a few of these features and visualize how they realte to SalePrie. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attr = ['SalePrice','OverallQual','GarageCars','YearBuilt','TotalBsmtSF']\n",
    "scatter_matrix(df[attr], figsize=(13,13))"
   ]
  },
  {
   "source": [
    "If you look at the top row of the scatter matrix, you can see the positive relationship between SalePrice and the other highly predictive features. They make a certain amount of sense too; improved quality, more luxurious and spacious additions (like basements and garages), and newer buildings would often sell for more than their competitors. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.0: Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3.1: Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Missing values in this dataset are not random; instead they signal that the observation does not have the optional addon that is being measured. The simple solution here is to create a 'None' label, which holds that information. That said, this only works for categorical features. This becomes a problem for discrete features like 'GarageYrBlt', which has 81 missing values. I chose to fill this by stating that the house had built one in 1900, the earliest year in the dataset. This decision was made because a value needed to be there, 0 would have disrupted the feature, and, assuming a linear relationship with SalePrice, having an ancient garage is the closest we can manage to having none. I'll show the resulting relationship below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[noms + ords] = df[noms+ords].fillna(\"None\")\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(1900.0)\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "sns.scatterplot(data = df, x = \"GarageYrBlt\", y= \"SalePrice\")\n",
    "plt.title(\"Representing No Garage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "source": [
    "This leaves two sources of missing values, LotFrontage and MasVnrArea, which I will simply have filled in by the median value in the numeric pipeline."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3.2: Outliers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalePrice'].sort_values(ascending = False).head(10)"
   ]
  },
  {
   "source": [
    "The two outliers I found are homes that sold for more than $100,000 more than their nearest competitors, which are more grouped together with the rest of the observations. These values are extreme to the point that they would almost definitely having an outsized influence on the model, so they should be removed. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index = [691, 1182])"
   ]
  },
  {
   "source": [
    "### 3.3: SalePrice - Skewed Target Feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "As shown in 1.5, the target feature has a right skew; I'll address this by computing the log value of the feature, which should normalize its values. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "sns.histplot(df['SalePrice'].transform(np.log), color = 'blue')\n",
    "plt.title(\"The Transformed SalePrice Distribution\")\n",
    "\n",
    "df['SalePrice'] = df['SalePrice'].transform(np.log)"
   ]
  },
  {
   "source": [
    "### 3.4: Dropping Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Utilities'].value_counts()"
   ]
  },
  {
   "source": [
    "The Utilities feature would be helpful if it represented something besides homes with all public utilities; seeing how it is right now, it provides no useful information with the exception of its one observation that has no access to public water. Even then, that one record is not sizeable enough to be worthwhile. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Utilities' in df.columns:\n",
    "    df = df.drop('Utilities', axis = 1)\n",
    "if \"Utilities\" in noms:\n",
    "    noms.remove('Utilities')"
   ]
  },
  {
   "source": [
    "Additionally, the house ID attribute adds nothing of value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Id' in df.columns:\n",
    "    df = df.drop('Id', axis = 1)"
   ]
  },
  {
   "source": [
    "### 3.5: Numeric Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In addition to filling in any missing values with the median, the numeric pipeline will standardize the data by using the StandardScaler; this method is more resistant to outliers than MinMaxScaler. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('std', StandardScaler())])"
   ]
  },
  {
   "source": [
    "### 3.6: Full Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Categorical features will be split into binary attributes using the OneHotEncoder; ordinal features can be easily ranked, so they can be transformed into numeric values through the OrdinalEncoder. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attributes = list(heat.columns)\n",
    "ordinal_attributes = ords\n",
    "cat_attributes = noms\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, num_attributes),\n",
    "    (\"ord\", OrdinalEncoder(), ordinal_attributes),\n",
    "    (\"cats\", OneHotEncoder(), cat_attributes),\n",
    "])\n",
    "\n",
    "newdf = full_pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.DataFrame(newdf.todense())\n",
    "ytrain = df['SalePrice']"
   ]
  }
 ]
}